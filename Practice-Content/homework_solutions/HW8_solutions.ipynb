{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK: k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn import preprocessing, neighbors, grid_search, cross_validation\n",
    "from sklearn import model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/edwardlee/Desktop/df-sf-32/DS-SF-32/lessons/lesson-8/dataset-boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boston dataset concerns itself with housing values in suburbs of Boston.  A description of the dataset is as follows:\n",
    "\n",
    "- CRIM: per capita crime rate by town\n",
    "- ZN: proportion of residential land zoned for lots over 25,000 sqft\n",
    "- INDUS: proportion of non-retail business acres per town\n",
    "- CHAS: Charles River binary/dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- NOX: nitric oxides concentration (parts per 10 million)\n",
    "- RM: average number of rooms per dwelling\n",
    "- AGE: proportion of owner-occupied units built prior to 1940\n",
    "- DIS: weighted distances to five Boston employment centers\n",
    "- RAD: index of accessibility to radial highways\n",
    "- TAX: full-value property-tax rate (per ten thousands of dollars)\n",
    "- PTRATIO: pupil-teacher ratio by town\n",
    "- B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT: % lower status of the population\n",
    "- MEDV: Median value of owner-occupied homes (in thousands of dollars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.  \n",
    "+ Let's first categorize `MEDV` to 4 groups: Bottom 20% as Level 1, next 30% as Level 2, next 30% categorized as Level 3, and the top 20% as Level 4.  \n",
    "+ Please create a new variable `MEDV_Category` that stores the level number\n",
    "+ Remember the quantile function\n",
    "+ Remember how to segment your pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df['MEDV'].quantile(.2)\n",
    "print df['MEDV'].quantile(.5)\n",
    "print df['MEDV'].quantile(.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q1 = df['MEDV'].quantile(.2)\n",
    "q2 = df['MEDV'].quantile(.5)\n",
    "q3 = df['MEDV'].quantile(.8)\n",
    "\n",
    "def classify_medv(x):\n",
    "    if x < q1:\n",
    "        return 0\n",
    "    elif x >= q1 and x < q2:\n",
    "        return 1\n",
    "    elif x >= q2 and x < q3:\n",
    "        return 2\n",
    "    elif x >= q3:\n",
    "        return 3\n",
    "\n",
    "df['medv_category'] = df['MEDV'].map(classify_medv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our goal is to predict `MEDV_Category` based on `RM`, `PTRATIO`, and `LSTAT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.  \n",
    "\n",
    "+ First normalize `RM`, `PTRATIO`, and `LSTAT`.  \n",
    "+ By normalizing, we mean to scale each variable between 0 and 1 with the lowest value as 0 and the highest value as 1\n",
    "\n",
    "+ Check out the documentation for MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "df['RM'] = mms.fit_transform(df['RM'])\n",
    "df['PTRATIO'] = mms.fit_transform(df['PTRATIO'])\n",
    "df['LSTAT'] = mms.fit_transform(df['LSTAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.  \n",
    "\n",
    "+ Run a k-NN classifier with 5 nearest neighbors and report your misclassification error; set weights to uniform\n",
    "+ Calculate your misclassification error on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[['RM', 'PTRATIO', 'LSTAT']]\n",
    "y = df['medv_category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, stratify=y, train_size=.80)\n",
    "print trainX.shape, testX.shape\n",
    "print trainY.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = knn.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cnf_mtx = confusion_matrix(testY, y_predict)\n",
    "print cnf_mtx\n",
    "\n",
    "print classification_report(y_predict, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print 'Error Rate', 1 - accuracy_score(testY, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. \n",
    "+ Is this error reliable? \n",
    "+ What could we do to make it better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict_full = model.predict(X)\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnf_mtx = confusion_matrix(y, y_predict_full)\n",
    "print cnf_mtx\n",
    "\n",
    "print classification_report(y_predict_full, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Error Rate', 1 - accuracy_score(y, y_predict_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:1.5em; color:blue'>Based off of these 3 predictors, the algorithm on the entire dataset shows a 23% error rate, which isn't great. We will need to perform grid search to optimize our algorithm.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5.  \n",
    "+ Now use 10-fold cross-validation to choose the most efficient `k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_neighbors':range(2,30),\n",
    "    'weights':['uniform', 'distance']\n",
    "}\n",
    "gs = grid_search.GridSearchCV(knn, params, cv=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6.  \n",
    "\n",
    "+ Explain your findings\n",
    "+ What were your best parameters?\n",
    "+ What was the best k?\n",
    "+ What was the best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'best estimator: ', gs.best_estimator_\n",
    "print 'best param: ', gs.best_params_\n",
    "print 'best score: ', gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7.  \n",
    "\n",
    "+ Train your model with the optimal `k` you found above \n",
    "+ (don't worry if it changes from time to time - if that is the case use the one that is usually the best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn_best = neighbors.KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=18, p=2,\n",
    "           weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_best = knn_best.fit(trainX, trainY)\n",
    "predict_best = model_best.predict(testX)\n",
    "print 'error: ', 1 - model_best.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_best_full = model_best.predict(X)\n",
    "print 'error: ', 1 - model_best.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print confusion_matrix(testY, predict_best)\n",
    "print '=================================================='\n",
    "print confusion_matrix(y, predict_best_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print classification_report(testY, predict_best)\n",
    "print '=================================================='\n",
    "print classification_report(y, predict_best_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:1.5em; color:blue'>The grid search performed much better with a 5.7% error rate on the full dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8.  \n",
    "\n",
    "+ After training your model with that `k`, \n",
    "+ use it to *predict* the class of a neighborhood with `RM = 2`, `PRATIO = 19`, and `LSTAT = 3.5`\n",
    "+ If you are confused, check out the sklearn documentation for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_best.predict([2, 19, 3.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RM: average number of rooms per dwelling\n",
    "- PTRATIO: pupil-teacher ratio by town\n",
    "- LSTAT: % lower status of the population\n",
    "- MEDV: Median value of owner-occupied homes (in thousands of dollars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='font-size:1.5em; color:blue'>With 2 dwelling rooms, a 19:1 pupil:teacher ratio and 3.5% lower status predicts a quantile between 20-50% in median income.</span>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
